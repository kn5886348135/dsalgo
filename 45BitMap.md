位图：如何实现网页爬虫中的URL去重功能？
===


&emsp;&emsp;网页爬虫是搜索引擎中的非常重要的系统，负责爬取几十亿、上百亿的网页。爬虫的工作原理是，通过解析已经爬取页面中的网页链接，然后再爬取这些链接对应的网页。而同一个网页链接有可能被包含在多个页面中，这就会导致爬虫在爬取的过程中，重复爬取相同的网页。如果你是一名负责爬虫的工程师，你会如何避免这些重复的爬取呢？

&emsp;&emsp;最容易想到的方法就是，记录已经爬取的网页链接（也就是 URL），在爬取一个新的网页之前，拿它的链接，在已经爬取的网页链接列表中搜索。如果存在，那就说明这个网页已经被爬取过了；如果不存在，那就说明这个网页还没有被爬取过，可以继续去爬取。等爬取到这个网页之后，将这个网页的链接添加到已经爬取的网页链接列表了。

#### 算法解析

&emsp;&emsp;这个问题要处理的对象是网页链接，也就是 URL，需要支持的操作有两个，添加一个 URL 和查询一个 URL。除了这两个功能性的要求之外，在非功能性方面，还要求这两个操作的执行效率要尽可能高。除此之外，因为处理的是上亿的网页链接，内存消耗会非常大，所以在存储效率上，要尽可能地高效。

&emsp;&emsp;散列表、红黑树、跳表这些动态数据结构，都能支持快速地插入、查找数据，但是对内存消耗方面，是否可以接受呢？

&emsp;&emsp;拿散列表来举例。假设要爬取 10 亿个网页（像 Google、百度这样的通用搜索引擎，爬取的网页可能会更多），为了判重，把这 10 亿网页链接存储在散列表中。你来估算下，大约需要多少内存？

&emsp;&emsp;假设一个 URL 的平均长度是 64 字节，那单纯存储这 10 亿个 URL，需要大约 60GB 的内存空间。因为散列表必须维持较小的装载因子，才能保证不会出现过多的散列冲突，导致操作的性能下降。而且，用链表法解决冲突的散列表，还会存储链表指针。所以，如果将这 10 亿个 URL 构建成散列表，那需要的内存空间会远大于 60GB，有可能会超过 100GB。

&emsp;&emsp;对于一个大型的搜索引擎来说，即便是 100GB 的内存要求，其实也不算太高，可以采用分治的思想，用多台机器（比如 20 台内存是 8GB 的机器）来存储这 10 亿网页链接。

&emsp;&emsp;对于爬虫的 URL 去重这个问题，分治加散列表的思路，已经是可以实实在在工作的了。

&emsp;&emsp;散列表中添加、查找数据的时间复杂度已经是 O(1)，还能有进一步优化的空间吗？时间复杂度并不能完全代表代码的执行时间。大 O 时间复杂度表示法，会忽略掉常数、系数和低阶，并且统计的对象是语句的频度。不同的语句，执行时间也是不同的。时间复杂度只是表示执行时间随数据规模的变化趋势，并不能度量在特定的数据规模下，代码执行时间的多少。

&emsp;&emsp;如果时间复杂度中原来的系数是 10，现在能够通过优化，将系数降为 1，那在时间复杂度没有变化的情况下，执行效率就提高了 10 倍。对于实际的软件开发来说，10 倍效率的提升，显然是一个非常值得的优化。

&emsp;&emsp;如果用基于链表的方法解决冲突问题，散列表中存储的是 URL，那当查询的时候，通过哈希函数定位到某个链表之后，还需要依次比对每个链表中的 URL。这个操作是比较耗时的，主要有两点原因。

1. 链表中的结点在内存中不是连续存储的，所以不能一下子加载到 CPU 缓存中，没法很好地利用到 CPU 高速缓存，所以数据访问性能方面会打折扣。

2. 链表中的每个数据都是 URL，而 URL 不是简单的数字，是平均长度为 64 字节的字符串。也就是说，要让待判重的 URL，跟链表中的每个 URL，做字符串匹配。显然，这样一个字符串匹配操作，比起单纯的数字比对，要慢很多。所以，基于这两点，执行效率方面肯定是有优化空间的。

&emsp;&emsp;对于内存消耗方面的优化，除了刚刚这种基于散列表的解决方案，还可以考虑**布隆过滤器**（Bloom Filter）。

&emsp;&emsp;布隆过滤器是基于**位图**（BitMap）这种存储结构的，是对位图的一种改进。

&emsp;&emsp;假设有 1 千万个整数，整数的范围在 1 到 1 亿之间。如何快速查找某个整数是否在这 1 千万个整数中呢？

&emsp;&emsp;这个问题还是可以用散列表来解决。不过，可以使用一种比较“特殊”的散列表，那就是位图。申请一个大小为 1 亿、数据类型为布尔类型（true 或者 false）的数组。将这 1 千万个整数作为数组下标，将对应的数组值设置成 true。比如，整数 5 对应下标为 5 的数组值设置为 true，也就是 array[5]=true。

&emsp;&emsp;当查询某个整数 K 是否在这 1 千万个整数中的时候，只需要将对应的数组值 array[K] 取出来，看是否等于 true。如果等于 true，那说明 1 千万整数中包含这个整数 K；相反，就表示不包含这个整数 K。

&emsp;&emsp;很多语言中提供的布尔类型，大小是 1 个字节的，并不能节省太多内存空间。表示 true 和 false 两个值，只需要用一个二进制位（bit）就可以了。那如何通过编程语言，来表示一个二进制位呢？

&emsp;&emsp;这里就要用到位运算了。可以借助编程语言中提供的数据类型，比如 int、long、char 等类型，通过位运算，用其中的某个位表示某个数字。
```Java
public class BitMap { // Java 中 char 类型占 16bit，也即是 2 个字节
  private char[] bytes;
  private int nbits;

  public BitMap(int nbits) {
    this.nbits = nbits;
    this.bytes = new char[nbits/16+1];
  }

  public void set(int k) {
    if (k > nbits) return;
    int byteIndex = k / 16;
    int bitIndex = k % 16;
    bytes[byteIndex] |= (1 << bitIndex);
  }

  public boolean get(int k) {
    if (k > nbits) return false;
    int byteIndex = k / 16;
    int bitIndex = k % 16;
    return (bytes[byteIndex] & (1 << bitIndex)) != 0;
  }
}
```
&emsp;&emsp;位图通过数组下标来定位数据，所以，访问效率非常高。而且，每个数字用一个二进制位来表示，在数字范围不大的情况下，所需要的内存空间非常节省。

&emsp;&emsp;比如刚刚那个例子，如果用散列表存储这 1 千万的数据，数据是 32 位的整型数，也就是需要 4 个字节的存储空间，那总共至少需要 40MB 的存储空间。如果通过位图的话，数字范围在 1 到 1 亿之间，只需要 1 亿个二进制位，也就是 12MB 左右的存储空间就够了。

&emsp;&emsp;这里有个假设，就是数字所在的范围不是很大。如果数字的范围很大，比如刚刚那个问题，数字范围不是 1 到 1 亿，而是 1 到 10 亿，那位图的大小就是 10 亿个二进制位，也就是 120MB 的大小，消耗的内存空间，不降反增。

&emsp;&emsp;布隆过滤器就是为了解决刚刚这个问题，对位图这种数据结构的一种改进。

&emsp;&emsp;还是刚刚那个例子，数据个数是 1 千万，数据的范围是 1 到 10 亿。布隆过滤器的做法是，仍然使用一个 1 亿个二进制大小的位图，然后通过哈希函数，对数字进行处理，让它落在这 1 到 1 亿范围内。比如把哈希函数设计成 f(x)=x%n。其中，x 表示数字，n 表示位图的大小（1 亿），也就是，对数字跟位图的大小进行取模求余。

&emsp;&emsp;哈希函数会存在冲突的问题啊，一亿零一和 1 两个数字，经过你刚刚那个取模求余的哈希函数处理之后，最后的结果都是 1。这样我就无法区分，位图存储的是 1 还是一亿零一了。

&emsp;&emsp;为了降低这种冲突概率，当然可以设计一个复杂点、随机点的哈希函数。除此之外，还有其他方法吗？来看布隆过滤器的处理方法。既然一个哈希函数可能会存在冲突，那用多个哈希函数一块儿定位一个数据，是否能降低冲突的概率呢？

&emsp;&emsp;使用 K 个哈希函数，对同一个数字进行求哈希值，那会得到 K 个不同的哈希值，分别记作 $X1$，$X2$，$X3$，…，X~K~。把这 K 个数字作为位图中的下标，将对应的 $BitMap[X1]$，$BitMap[X2]$，$BitMap[X3]$，…，$BitMap[XK]$ 都设置成 true，也就是说，用 K 个二进制位，来表示一个数字的存在。

&emsp;&emsp;当要查询某个数字是否存在的时候，用同样的 K 个哈希函数，对这个数字求哈希值，分别得到 Y1，Y2，Y3，…，YK。看这 K 个哈希值，对应位图中的数值是否都为 true，如果都是 true，则说明，这个数字存在，如果有其中任意一个不为 true，那就说明这个数字不存在。

<img src="assert/KHashInBloomFilterA.jpg" alt="布隆过滤器的多个哈希函数" style="zoom:50%;" />

&emsp;&emsp;对于两个不同的数字来说，经过一个哈希函数处理之后，可能会产生相同的哈希值。但是经过 K 个哈希函数处理之后，K 个哈希值都相同的概率就非常低了。尽管采用 K 个哈希函数之后，两个数字哈希冲突的概率降低了，但是，这种处理方式又带来了新的问题，那就是容易误判。

<img src="assert/KHashInBloomFilterB.jpg" alt="布隆过滤器的多个哈希函数" style="zoom:50%;" />

&emsp;&emsp;布隆过滤器的误判有一个特点，那就是，它只会对存在的情况有误判。如果某个数字经过布隆过滤器判断不存在，那说明这个数字真的不存在，不会发生误判；如果某个数字经过布隆过滤器判断存在，这个时候才会有可能误判，有可能并不存在。不过，只要调整哈希函数的个数、位图大小跟要存储数字的个数之间的比例，那就可以将这种误判的概率降到非常低。

&emsp;&emsp;尽管布隆过滤器会存在误判，但是，这并不影响它发挥大作用。很多场景对误判有一定的容忍度。比如今天要解决的爬虫判重这个问题，即便一个没有被爬取过的网页，被误判为已经被爬取，对于搜索引擎来说，也并不是什么大事情，是可以容忍的，毕竟网页太多了，搜索引擎也不可能 100% 都爬取到。

&emsp;&emsp;用布隆过滤器来记录已经爬取过的网页链接，假设需要判重的网页有 10 亿，那可以用一个 10 倍大小的位图来存储，也就是 100 亿个二进制位，换算成字节，那就是大约 1.2GB。之前用散列表判重，需要至少 100GB 的空间。相比来讲，布隆过滤器在存储空间的消耗上，降低了非常多。

&emsp;&emsp;布隆过滤器用多个哈希函数对同一个网页链接进行处理，CPU 只需要将网页链接从内存中读取一次，进行多次哈希计算，理论上讲这组操作是 CPU 密集型的。而在散列表的处理方式中，需要读取散列冲突拉链的多个网页链接，分别跟待判重的网页链接，进行字符串匹配。这个操作涉及很多内存数据的读取，所以是内存密集型的。知道 CPU 计算可能是要比内存访问更快速的，所以，理论上讲，布隆过滤器的判重方式，更加快速。

#### 总结引申

&emsp;&emsp;搜索引擎爬虫网页去重问题的解决，可以用散列表、到位图、布隆过滤器。布隆过滤器非常适合这种不需要 100% 准确的、允许存在小概率误判的大规模判重场景。除了爬虫网页去重这个例子，还有比如统计一个大型网站的每天的 UV 数，也就是每天有多少用户访问了网站，就可以使用布隆过滤器，对重复访问的用户，进行去重。

&emsp;&emsp;布隆过滤器的误判率，主要跟哈希函数的个数、位图的大小有关。当往布隆过滤器中不停地加入数据之后，位图中不是 true 的位置就越来越少了，误判率就越来越高了。所以，对于无法事先知道要判重的数据个数的情况，需要支持自动扩容的功能。

&emsp;&emsp;当布隆过滤器中，数据个数与位图大小的比例超过某个阈值的时候，就重新申请一个新的位图。后面来的新数据，会被放置到新的位图中。但是，如果要判断某个数据是否在布隆过滤器中已经存在，就需要查看多个位图，相应的执行效率就降低了一些。

&emsp;&emsp;位图、布隆过滤器应用如此广泛，很多编程语言都已经实现了。比如 Java 中的 BitSet 类就是一个位图，Redis 也提供了 BitMap 位图类，Google 的 Guava 工具包提供了 BloomFilter 布隆过滤器的实现。

#### 课后思考

&emsp;&emsp;假设有 1 亿个整数，数据范围是从 1 到 10 亿，如何快速并且省内存地给这 1 亿个数据从小到大排序？

&emsp;&emsp;还记得在哈希函数（下）讲过的利用分治思想，用散列表以及哈希函数，实现海量图库中的判重功能吗？如果允许小概率的误判，那是否可以用今天的布隆过滤器来解决呢？你可以参照当时的估算方法，重新估算下，用布隆过滤器需要多少台机器？




bloom filter: False is always false. True is maybe true.







课后思考题1

传统的做法：1亿个整数，存储需要400M空间，排序时间复杂度最优 N×log(N)

使用位图算法：数字范围是1到10亿，用位图存储125M就够了，然后将1亿个数字依次添加到位图中，然后再将位图按下标从小到大输出值为1的下标，排序就完成了，时间复杂度为 N






位图代码的实现一开始没看懂，请教了下身边一位大神同事才搞懂，原来char类型存储数字的时候，只占1个字节，也就是8位。所以计算的时候都是除8或者模8。希望我的回答可以帮助其他跟我一样基础薄弱的同学，共同进步







这个char代码最好还是用图解比较好理解，纯代码看不懂。
我这里有另外一个位的图解计算过程，再去看代码，你就会秒懂
https://mp.weixin.qq.com/s/xxauNrJY9HlVNvLrL5j2hg





第一题，数字重复了，有什么好方法处理吗
作者回复: 对于重复的 可以再维护一个小的散列表 记录出现次数超过1次的数据以及对应的个数






1亿个整数 如果完全读入内存大约是0.4G的样子 可以直接快排排序 
通过位图方式开辟一个十亿大小的位图缩小到0.125g的样子,虽然数字只有一亿个,但是却要检查1到10亿之间的数字是否存在再输出即可达到排序






在线上环境，采用redis的set进行去重，效果还是不错的






直观上感觉位图有点像学排序时桶的概念，所以使用位图也可以实现类似于桶排序的效率。






这个位图很精妙，因为编程语言没有提供bit类型，所以使用byte进行位运算的方式，巧妙的利用每一位，以达到减少内存开辟的消耗的问题





争哥，我想到了通过hash算法将String转换为int类型数据，然后再将int数据位运算存储到位图上，可是这个hash算法，也可能会出现散列冲突啊，不同的String有可能是同一个int，然后反应到位图上就是相同的bit位了。





将数字 A 的第 k 位设置为1：A = A | (1 << (k - 1))
将数字 A 的第 k 位设置为0：A = A & ~(1 << (k - 1))
检测数字 A 的第 k 位：A & (1 << (k - 1)) != 0
用于理解bitmap中代码





```Java
import java.util.Random;

public class BitMap {
    private int[] bits;
    private int[] input;

    public BitMap(int n, int[] input) {
        bits = new int[n];
        this.input = input;
    }
    
    public void setBit(int n) {
        int offset = n / 32;
        int value = n % 32;
        bits[offset] |= (1 << value);
    }
    
    public boolean getBit(int n) {
        int offset = n / 32;
        int value = n % 32;
        return (bits[offset] & (1 << value)) != 0;
    }
    
    /**
     * 排序
     * 
     * @param n
     * 是数组的存储整数范围
     * @param input
     * 输入的未排序数组
     * @return 有序的数组范围
     */
    public int sort(int n, int[] input) {
        int j = 0;
        for (int i = 1; i <= 10 * n; i++) {
            if (getBit(i)) {
                input[j++] = i;
            }
        }
        return j;
    }
    
    public static void main(String[] args) {
        int n = 1000000000;
        int[] input = new int[n];
        Random r = new Random();
        for (int i = 0; i < n; i++) {
            input[i] = r.nextInt(10 * n - 1) + 1;
        }
        BitMap bitMap = new BitMap(10 * n, input);
        for (int i = 0; i < n; i++) {
            bitMap.setBit(input[i]);
        }
        int size = bitMap.sort(n, input);
        for (int i = 0; i < size; i++)
            System.out.print(input[i] + ",");
    }
}
```







思考题1:用10亿个位的位图存储这1亿个数，然后直接按脚标从0到10亿顺序遍历整个位图，如果位为1，则打印脚标，打印出来的就是排好序的1亿个数字

思考题2:用位图的话。一个机器应该就够了





老师，按照你的讲解我写了一个简单的布隆过滤器， 使用了3个简单的哈希函数，判错率在0.9左右
不知道是否是属于偏高了，这是代码，可以的话帮忙看看是否正确https://github.com/MarvinLe/tools/tree/master/BloomFilter
作者回复: 判错旅太高了 哈希函数不够随机均匀？位图不够大？








第一题可以理解为计数排序和位图的结合







王老师，看了您定义的BitMap数据结构，该结构的类有两个私有成员变量，其中一个变量的类型是int，int在java中是用4个字节的内存空间来存储吧？所以每个位图对象应该至少占了2个字节+4个字节的内存空间吧？
作者回复: 不 位图是一种索引结构 对象本事存储在另外的地方 在计算位图大小的时候不会把对象本事占用的内存大小算进去的





争哥，int类型数据存bitmap可以这么位运算，那String类型的是怎么位运算的呢？Java里面也只有"123"这样的字符串可以转成int呀。布隆过滤器对url这种字符串是怎么位运算的，或者说怎么转成int类型呢？
作者回复: 先通过哈希函数计算哈希值





请问争哥，new char[nbits/16+1]这里面为什么要做这个计算，看不懂啊
作者回复: char是16位的